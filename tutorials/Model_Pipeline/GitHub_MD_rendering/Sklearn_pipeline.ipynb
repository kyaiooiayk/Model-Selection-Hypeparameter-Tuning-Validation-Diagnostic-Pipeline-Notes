{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**What?** How to use pipeline in sklearn and AVOID data leakage\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "An easy trap to fall into in applied machine learning is leaking data from \n",
    "your training dataset to your test dataset. To avoid this trap you need a \n",
    "robust test harness with strong separation of training and testing. \n",
    "Pipelines help you prevent data leakage in your test harness by ensuring \n",
    "that data preparation like standardization is constrained to each fold\n",
    "of your cross validation procedure.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python modules\n",
    "from pandas import read_csv\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import KFold\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional cosmetic function\n",
    "def myPrint(string, c = \"blue\"):    \n",
    "    \"\"\"My version of the python-native print command.\n",
    "    \n",
    "    Print in bold and red tect\n",
    "    \"\"\"\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(c, '**'+ string + '**' )    \n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue'>**Importing dataset**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:  (768, 8)\n",
      "Labels size:  (768,)\n"
     ]
    }
   ],
   "source": [
    "myPrint(\"Importing dataset\")\n",
    "filename = './datasetCollections/pima-indians-diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class'] \n",
    "dataframe = read_csv(filename, names = names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "num_folds = 10\n",
    "print(\"Input size: \", X.shape)\n",
    "print(\"Labels size: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue'>**Create a pipeline that standardizes the data then creates a model**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0.7669685577580315\n",
      "\n",
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_check_fit_params', '_check_n_features', '_estimator_type', '_final_estimator', '_fit', '_get_param_names', '_get_params', '_get_tags', '_inverse_transform', '_iter', '_log_message', '_more_tags', '_pairwise', '_replace_estimator', '_repr_html_', '_repr_html_inner', '_repr_mimebundle_', '_required_parameters', '_set_params', '_sk_visual_block_', '_transform', '_validate_data', '_validate_names', '_validate_steps', 'classes_', 'decision_function', 'fit', 'fit_predict', 'fit_transform', 'get_params', 'inverse_transform', 'memory', 'n_features_in_', 'named_steps', 'predict', 'predict_log_proba', 'predict_proba', 'score', 'score_samples', 'set_params', 'steps', 'transform', 'verbose']\n",
      "<bound method Pipeline.get_params of Pipeline(steps=[('standardize', StandardScaler()),\n",
      "                ('lda', LinearDiscriminantAnalysis())])>\n"
     ]
    }
   ],
   "source": [
    "myPrint(\"Create a pipeline that standardizes the data then creates a model\")\n",
    "\n",
    "\"\"\"\n",
    "The pipeline is defined with two steps:\n",
    "[1] Standardize the data\n",
    "[2] Learn a Linear Discriminant Analysis model\n",
    "\n",
    "The pipeline is then evaluated using 10-fold cross validation\n",
    "\"\"\"\n",
    "\n",
    "# Create pipeline\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('lda', LinearDiscriminantAnalysis()))\n",
    "pipeLineModel = Pipeline(estimators)\n",
    "# evaluate pipeline\n",
    "kfold = KFold(n_splits = 10, shuffle = True, random_state = 7)\n",
    "results = cross_val_score(pipeLineModel, X, Y, cv = kfold)\n",
    "print(\"Mean: \", results.mean())\n",
    "\n",
    "print(\"\")\n",
    "print(dir(model))\n",
    "print(model.get_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<span style='color:blue'>**Features extraction within the pipeline**</span>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 0.7721633629528366\n"
     ]
    }
   ],
   "source": [
    "myPrint(\"Features extraction within the pipeline\")\n",
    "\n",
    "\"\"\"\n",
    "Feature extraction is another procedure that is susceptible to data leakage.\n",
    "feature extraction procedures must be restricted to the data in your training dataset.\n",
    "FeatureUnion which allows the results of multiple feature selection and extraction \n",
    "procedures to be combined into a larger dataset on which a model can be trained.\n",
    "\n",
    "The code below does 4 steps:\n",
    "[1] Feature Extraction with Principal Component Analysis (3 features)\n",
    "[2] Feature Extraction with Statistical Selection (6 features)\n",
    "[3] Feature Union\n",
    "[4] Learn a Logistic Regression Model\n",
    "\"\"\"\n",
    "\n",
    "# Create feature union\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components = 3)))\n",
    "features.append(('select_best', SelectKBest(k = 6)))\n",
    "feature_union = FeatureUnion(features)\n",
    "\n",
    "# Create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union)) \n",
    "estimators.append(('logistic', LogisticRegression(max_iter = 250)))\n",
    "model = Pipeline(estimators)\n",
    "\n",
    "# Evaluate pipeline\n",
    "kfold = KFold(n_splits=10, shuffle = True, random_state=7)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Mean\", results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://machinelearningmastery.com/data-preparation-without-data-leakage/\n",
    "\n",
""   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "trainingAI",
   "language": "python",
   "name": "trainingai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
